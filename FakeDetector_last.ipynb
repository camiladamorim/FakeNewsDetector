{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FakeDetector-last.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW36GAuGSsTG"
      },
      "source": [
        "reliable and unreliable sources according to:\n",
        "\n",
        "* https://www.forbes.com/sites/berlinschoolofcreativeleadership/2017/02/01/10-journalism-brands-where-you-will-find-real-facts-rather-than-alternative-facts/?sh=1e2c31e5e9b5\n",
        "* https://towardsdatascience.com/how-statistically-biased-is-our-news-f28f0fab3cb3\n",
        "* https://www.adfontesmedia.com/interactive-media-bias-chart-2/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK1iWwa5cIp_"
      },
      "source": [
        "\n",
        "reliable_sources = ['latest news',\n",
        "                    'Microsoft news',\n",
        "                    'BBC', \n",
        "                    'The Wall Street Journal',\n",
        "                    'The New York Times',\n",
        "                    'The New Yorker',\n",
        "                    'The Economist',\n",
        "                    'Politico',\n",
        "                    'The Atlantic',\n",
        "                    'National Review',\n",
        "                    'The Weekly Standard',\n",
        "                    'The New Republic',\n",
        "                    'The Nation',\n",
        "                    'Reuters',\n",
        "                    'ABC News',\n",
        "                    'The Advocate',\n",
        "                    'Bloomberg',\n",
        "                    'National Public Radio',\n",
        "                    'The Hill',\n",
        "                    'LA Times',\n",
        "                    'CBS',\n",
        "                    'Mercury news',\n",
        "                    'The Denver Post',\n",
        "                    'Nola',\n",
        "                    'Stars and stripes',\n",
        "                    'Patch',\n",
        "                    'BNO',\n",
        "                    'Associated Press News',\n",
        "                    'CNN',\n",
        "                    'MSNBC',\n",
        "                    'Local']\n",
        "\n",
        "\n",
        "unreliable_sources = ['World Truth TV',\n",
        "                      'National Enquirer',\n",
        "                      'The Gateway Pundit',\n",
        "                      'InfoWars',\n",
        "                      'NewsPunch',\n",
        "                      'Wonkette',\n",
        "                      'WorldNetDaily',\n",
        "                      'Twitchy',\n",
        "                      'Palmer Report',\n",
        "                      'PJ Media',\n",
        "                      'Bipartisan Report',\n",
        "                      'Occupy Democrats',\n",
        "                      'Breitbart',\n",
        "                      'Alternet',\n",
        "                      'Conservative Review',\n",
        "                      'The American Spectator',\n",
        "                      'The Federalist',\n",
        "                      'ShareBlue',\n",
        "                      'Crooks and Liars',\n",
        "                      'American Thinker',\n",
        "                      'Daily Kos',\n",
        "                      'Daily Caller',\n",
        "                      'Daily Mail',\n",
        "                      'Daily Signal',\n",
        "                      'Alternet',\n",
        "                      'Daily Kos'\n",
        "                      'Truthout',\n",
        "                      'Democracy Now',\n",
        "                      'Lifezette',\n",
        "                      'NewsMax',\n",
        "                      'American Thinker',\n",
        "                      'Before it is news',\n",
        "                      'The Week']\n",
        "\n",
        "\n",
        "red_flag_terms = [\"fake\",\n",
        "                  \"Fake\",\n",
        "                  \"alse claim\",\n",
        "                  \"False Claim\",\n",
        "                  \"isinformation\",\n",
        "                  \"rong info\",\n",
        "                  \"ncorrect info\",\n",
        "                  \"nformation is incorrect\",\n",
        "                  \"his is incorrect\",\n",
        "                  \"his is not correct\",\n",
        "                  \"his is false\",\n",
        "                  \"his is not true\",\n",
        "                  \"ata is incorrect\",\n",
        "                  \"nformation is not true\",\n",
        "                  \"nformation is not correct\",\n",
        "                  \"ata is not correct\",\n",
        "                  \"nformation is not correct\",\n",
        "                  \"nformation isn't true\",\n",
        "                  \"not telling the truth\"\n",
        "                  \"t true\",\n",
        "                  \"biased\",\n",
        "                  \"news bias\",\n",
        "                  \"edia bias\",\n",
        "                  \"edia Bias\",\n",
        "                  \"hiding info\",\n",
        "                  \"hiding the truth\",\n",
        "                  \"hide info\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQJM1_RNmd00"
      },
      "source": [
        "import urllib\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import gdown\n",
        "import pandas as pd\n",
        "\n",
        "class FakeFinder():\n",
        "    def __init__(self,search_str):\n",
        "        self.run(search_str)\n",
        "\n",
        "    def get_results(self,search_str):\n",
        "        url_prefix = \"https://www.google.com/search?client=firefox-b-d&q=\"\n",
        "        url = url_prefix + \"+\".join(search_str.split())\n",
        "        resp = requests.get(url)\n",
        "        if resp.status_code != 200:\n",
        "            raise Exception(\"connection error\")\n",
        "        soup = BeautifulSoup(resp.content, \"html.parser\")\n",
        "        divs=soup.find_all('div')\n",
        "        results = []\n",
        "        for div in divs:\n",
        "            if (div.find('a') and div.find('a')['href'][:7] == \"/url?q=\" and div.find('h3')):\n",
        "                result_link = div.find('a')['href']\n",
        "                title = div.find('h3').text\n",
        "                summary = div.find('a').parent.parent.text\n",
        "                date = div.find('a').parent.next_sibling.next_sibling.find(\"span\")\n",
        "                if date is not None:\n",
        "                    date = date.text\n",
        "                item = {\"title\": title, \"link\": result_link, \"summary\": summary, \"date\": date}\n",
        "                results.append(item)\n",
        "        return results\n",
        "\n",
        "    def classify_results(self,results):\n",
        "        table=[[],[]]\n",
        "\n",
        "        for result in results:\n",
        "            table[0].append(result.get('summary'))\n",
        "\n",
        "        for result in results:\n",
        "            count=55\n",
        "        for term in red_flag_terms:\n",
        "            if term in result.get('summary'):\n",
        "                count=count-2\n",
        "        for term in unreliable_sources:\n",
        "            if term in result.get('summary'):\n",
        "                count=count-5\n",
        "        for term in reliable_sources:\n",
        "            if term in result.get('summary'):\n",
        "                count=count+5\n",
        "        table[1].append(count)\n",
        "\n",
        "        possible_fake_news='low probability'\n",
        "        for i in range(len(table[1])):\n",
        "            if 45<table[1][i]<50:\n",
        "                possible_fake_news='medium probability'\n",
        "            if table[1][i]<45:\n",
        "                possible_fake_news='high probability'\n",
        "        return(possible_fake_news)\n",
        "\n",
        "    def run(self,search_str):\n",
        "        results=self.get_results(search_str)\n",
        "        evaluation=self.classify_results(results)\n",
        "        print(evaluation)\n",
        "        return(evaluation)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC2-EcycxHGv",
        "outputId": "0758d928-3acd-4aaf-aa9b-cba96cc59111"
      },
      "source": [
        "fake=FakeFinder(\"fake biased trump shark \")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "low probability\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKnZB1pcxMuY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}